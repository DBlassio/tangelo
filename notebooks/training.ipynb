{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, Ridge\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score,accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "os.chdir(\"C:/Users/diego/Desktop/tangelo/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat__Gender_M</th>\n",
       "      <th>cat__Car_Y</th>\n",
       "      <th>cat__Realty_Y</th>\n",
       "      <th>cat__Work_phone_0</th>\n",
       "      <th>cat__Phone_0</th>\n",
       "      <th>cat__Email_1</th>\n",
       "      <th>cat__income_type_Commercial associate</th>\n",
       "      <th>cat__income_type_Pensioner</th>\n",
       "      <th>cat__income_type_State servant</th>\n",
       "      <th>cat__income_type_Student</th>\n",
       "      <th>...</th>\n",
       "      <th>cat__Occupation_type_Secretaries</th>\n",
       "      <th>cat__Occupation_type_Security staff</th>\n",
       "      <th>cat__Occupation_type_Waiters/barmen staff</th>\n",
       "      <th>num__Count_family_members</th>\n",
       "      <th>num__Years_Employed</th>\n",
       "      <th>num__Age</th>\n",
       "      <th>num__children_count</th>\n",
       "      <th>num__income_amount</th>\n",
       "      <th>education__education_type</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.217680</td>\n",
       "      <td>-0.437004</td>\n",
       "      <td>-0.935614</td>\n",
       "      <td>-0.579661</td>\n",
       "      <td>2.365845</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.217680</td>\n",
       "      <td>-0.437004</td>\n",
       "      <td>-0.935614</td>\n",
       "      <td>-0.579661</td>\n",
       "      <td>2.365845</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.217680</td>\n",
       "      <td>-0.461209</td>\n",
       "      <td>1.321517</td>\n",
       "      <td>-0.579661</td>\n",
       "      <td>-0.728827</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.314564</td>\n",
       "      <td>-0.447762</td>\n",
       "      <td>0.713828</td>\n",
       "      <td>-0.579661</td>\n",
       "      <td>0.818509</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.314564</td>\n",
       "      <td>-0.447762</td>\n",
       "      <td>0.713828</td>\n",
       "      <td>-0.579661</td>\n",
       "      <td>0.818509</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat__Gender_M  cat__Car_Y  cat__Realty_Y  cat__Work_phone_0  cat__Phone_0  \\\n",
       "0            1.0         1.0            1.0                0.0           1.0   \n",
       "1            1.0         1.0            1.0                0.0           1.0   \n",
       "2            1.0         1.0            1.0                1.0           1.0   \n",
       "3            0.0         0.0            1.0                1.0           0.0   \n",
       "4            0.0         0.0            1.0                1.0           0.0   \n",
       "\n",
       "   cat__Email_1  cat__income_type_Commercial associate  \\\n",
       "0           0.0                                    0.0   \n",
       "1           0.0                                    0.0   \n",
       "2           0.0                                    0.0   \n",
       "3           1.0                                    1.0   \n",
       "4           1.0                                    1.0   \n",
       "\n",
       "   cat__income_type_Pensioner  cat__income_type_State servant  \\\n",
       "0                         0.0                             0.0   \n",
       "1                         0.0                             0.0   \n",
       "2                         0.0                             0.0   \n",
       "3                         0.0                             0.0   \n",
       "4                         0.0                             0.0   \n",
       "\n",
       "   cat__income_type_Student  ...  cat__Occupation_type_Secretaries  \\\n",
       "0                       0.0  ...                               0.0   \n",
       "1                       0.0  ...                               0.0   \n",
       "2                       0.0  ...                               0.0   \n",
       "3                       0.0  ...                               0.0   \n",
       "4                       0.0  ...                               0.0   \n",
       "\n",
       "   cat__Occupation_type_Security staff  \\\n",
       "0                                  0.0   \n",
       "1                                  0.0   \n",
       "2                                  1.0   \n",
       "3                                  0.0   \n",
       "4                                  0.0   \n",
       "\n",
       "   cat__Occupation_type_Waiters/barmen staff  num__Count_family_members  \\\n",
       "0                                        0.0                  -0.217680   \n",
       "1                                        0.0                  -0.217680   \n",
       "2                                        0.0                  -0.217680   \n",
       "3                                        0.0                  -1.314564   \n",
       "4                                        0.0                  -1.314564   \n",
       "\n",
       "   num__Years_Employed  num__Age  num__children_count  num__income_amount  \\\n",
       "0            -0.437004 -0.935614            -0.579661            2.365845   \n",
       "1            -0.437004 -0.935614            -0.579661            2.365845   \n",
       "2            -0.461209  1.321517            -0.579661           -0.728827   \n",
       "3            -0.447762  0.713828            -0.579661            0.818509   \n",
       "4            -0.447762  0.713828            -0.579661            0.818509   \n",
       "\n",
       "   education__education_type  target  \n",
       "0                        3.0       0  \n",
       "1                        3.0       0  \n",
       "2                        2.0       0  \n",
       "3                        2.0       0  \n",
       "4                        2.0       0  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read Transformed Data\n",
    "df = pd.read_csv(\"./data/df_trans.csv\")\n",
    "df.rename(columns={'remainder__Target': 'target'}, inplace=True)\n",
    "df.drop(\"Unnamed: 0\",axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going test 5 different models in order to identify the best approach for our problem.\n",
    "- Applying Oversample in the training data\n",
    "- The objective metric is F1-Score based upon our imbalanced data problem.\n",
    "- Using GridSearch and 5 cross-validation\n",
    "- After that we are going to try to optimize it's hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   0%|          | 0/5 [00:00<?, ?it/s]c:\\Users\\diego\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\diego\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\diego\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\diego\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\diego\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\diego\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\diego\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\diego\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [21:09<03:58, 238.33s/it]  Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\diego\\anaconda3\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\diego\\anaconda3\\lib\\threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\diego\\anaconda3\\lib\\subprocess.py\", line 1479, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "  File \"c:\\Users\\diego\\anaconda3\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa0 in position 16: invalid start byte\n",
      "C:\\Users\\diego\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\diego\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 20202, number of negative: 20201\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10228\n",
      "[LightGBM] [Info] Number of data points in the train set: 40403, number of used features: 47\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500012 -> initscore=0.000050\n",
      "[LightGBM] [Info] Start training from score 0.000050\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 20202, number of negative: 20201\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10312\n",
      "[LightGBM] [Info] Number of data points in the train set: 40403, number of used features: 47\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500012 -> initscore=0.000050\n",
      "[LightGBM] [Info] Start training from score 0.000050\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 20201, number of negative: 20202\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10339\n",
      "[LightGBM] [Info] Number of data points in the train set: 40403, number of used features: 47\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499988 -> initscore=-0.000050\n",
      "[LightGBM] [Info] Start training from score -0.000050\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 20201, number of negative: 20202\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10305\n",
      "[LightGBM] [Info] Number of data points in the train set: 40403, number of used features: 47\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499988 -> initscore=-0.000050\n",
      "[LightGBM] [Info] Start training from score -0.000050\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 20202, number of negative: 20202\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10305\n",
      "[LightGBM] [Info] Number of data points in the train set: 40404, number of used features: 47\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 20202, number of negative: 20201\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10228\n",
      "[LightGBM] [Info] Number of data points in the train set: 40403, number of used features: 47\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500012 -> initscore=0.000050\n",
      "[LightGBM] [Info] Start training from score 0.000050\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 20202, number of negative: 20201\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10312\n",
      "[LightGBM] [Info] Number of data points in the train set: 40403, number of used features: 47\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500012 -> initscore=0.000050\n",
      "[LightGBM] [Info] Start training from score 0.000050\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 20201, number of negative: 20202\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10339\n",
      "[LightGBM] [Info] Number of data points in the train set: 40403, number of used features: 47\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499988 -> initscore=-0.000050\n",
      "[LightGBM] [Info] Start training from score -0.000050\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 20201, number of negative: 20202\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009893 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10305\n",
      "[LightGBM] [Info] Number of data points in the train set: 40403, number of used features: 47\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499988 -> initscore=-0.000050\n",
      "[LightGBM] [Info] Start training from score -0.000050\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 20202, number of negative: 20202\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10305\n",
      "[LightGBM] [Info] Number of data points in the train set: 40404, number of used features: 47\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 20202, number of negative: 20201\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10228\n",
      "[LightGBM] [Info] Number of data points in the train set: 40403, number of used features: 47\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500012 -> initscore=0.000050\n",
      "[LightGBM] [Info] Start training from score 0.000050\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 20202, number of negative: 20201\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10312\n",
      "[LightGBM] [Info] Number of data points in the train set: 40403, number of used features: 47\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500012 -> initscore=0.000050\n",
      "[LightGBM] [Info] Start training from score 0.000050\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 20201, number of negative: 20202\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008285 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10339\n",
      "[LightGBM] [Info] Number of data points in the train set: 40403, number of used features: 47\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499988 -> initscore=-0.000050\n",
      "[LightGBM] [Info] Start training from score -0.000050\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 20201, number of negative: 20202\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10305\n",
      "[LightGBM] [Info] Number of data points in the train set: 40403, number of used features: 47\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499988 -> initscore=-0.000050\n",
      "[LightGBM] [Info] Start training from score -0.000050\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 20202, number of negative: 20202\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10305\n",
      "[LightGBM] [Info] Number of data points in the train set: 40404, number of used features: 47\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 25252, number of negative: 25252\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10630\n",
      "[LightGBM] [Info] Number of data points in the train set: 50504, number of used features: 47\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [21:24<00:00, 256.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (Lasso):\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'best_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12672\\2760464658.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbest_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{model_name}:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Best Train Score (F1-Score): {info[\"best_score\"]:.4f}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Best Estimator: {info[\"best_estimator\"]}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# Predict on the test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'best_score'"
     ]
    }
   ],
   "source": [
    "# Features X and Y\n",
    "X, y = df.drop(\"target\",axis=1),df[\"target\"]\n",
    "y = y.astype('int')\n",
    "\n",
    "#Train-Test-Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, \n",
    "                                                    stratify=y, test_size=0.3,\n",
    "                                                    random_state = 10086)\n",
    "\n",
    "#SMOTE to address the imbalance problem but ONLY in the training data.\n",
    "#Test data remaing with the same distribution\n",
    "oversample = SMOTE()\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "X_train = pd.DataFrame(X_train, columns = X.columns)\n",
    "\n",
    "# Define the models to be evaluated\n",
    "models = [\n",
    "    ('Logistic Regression (Lasso)', LogisticRegression(max_iter=1000, penalty='l1', solver='saga')),\n",
    "    ('Logistic Regression (Ridge)', LogisticRegression(max_iter=1000, penalty='l2')),\n",
    "    ('Decision Tree', DecisionTreeClassifier()),\n",
    "    ('Random Forest', RandomForestClassifier()),\n",
    "    ('LightGBM', LGBMClassifier())\n",
    "]\n",
    "\n",
    "# Create a dictionary of parameter grids for each model\n",
    "param_grids = {\n",
    "    'Logistic Regression (Lasso)': {'model__C': [0.1, 1, 10]},\n",
    "    'Logistic Regression (Ridge)': {'model__C': [0.1, 1, 10]},\n",
    "    'Decision Tree': {'model__max_depth': [None, 10, 20]},\n",
    "    'Random Forest': {'model__n_estimators': [50, 100, 200]},\n",
    "    'LightGBM': {'model__n_estimators': [50, 100, 200]}\n",
    "}\n",
    "\n",
    "# Define F1-Score as the scoring metric\n",
    "scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# Create an empty dictionary to store the best models and their scores\n",
    "best_models = {}\n",
    "\n",
    "# Iterate over the models and perform GridSearchCV\n",
    "for model_name, model in tqdm(models,desc =\"Progress\"):\n",
    "    param_grid = param_grids[model_name]\n",
    "    pipeline = Pipeline([\n",
    "        ('model', model)\n",
    "    ])\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, scoring=scorer, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_models[model_name] = {\n",
    "        'best_estimator': grid_search.best_estimator_,\n",
    "        'train_score': grid_search.best_score_\n",
    "    }\n",
    "\n",
    "# Print the best models and their scores\n",
    "for model_name, info in best_models.items():\n",
    "    print(f'{model_name}:')\n",
    "    print(f'Best Train Score (F1-Score): {info[\"train_score\"]:.4f}')\n",
    "    print(f'Best Estimator: {info[\"best_estimator\"]}')\n",
    "    # Predict on the test set\n",
    "    y_pred = info[\"best_estimator\"].predict(X_test)\n",
    "    # Calculate the macro F1-score on the test set\n",
    "    test_score = f1_score(y_test, y_pred, average='macro')\n",
    "    print(f\"Best Test Score (F1-Score):{test_score:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (Lasso):\n",
      "Best Train Score (F1-Score): 0.6003\n",
      "Best Estimator: Pipeline(steps=[('model',\n",
      "                 LogisticRegression(C=10, max_iter=1000, penalty='l1',\n",
      "                                    solver='saga'))])\n",
      "Best Test Score (F1-Score):0.3750\n",
      "Logistic Regression (Ridge):\n",
      "Best Train Score (F1-Score): 0.6003\n",
      "Best Estimator: Pipeline(steps=[('model', LogisticRegression(C=1, max_iter=1000))])\n",
      "Best Test Score (F1-Score):0.3739\n",
      "Decision Tree:\n",
      "Best Train Score (F1-Score): 0.9897\n",
      "Best Estimator: Pipeline(steps=[('model', DecisionTreeClassifier())])\n",
      "Best Test Score (F1-Score):0.5642\n",
      "Random Forest:\n",
      "Best Train Score (F1-Score): 0.9927\n",
      "Best Estimator: Pipeline(steps=[('model', RandomForestClassifier(n_estimators=200))])\n",
      "Best Test Score (F1-Score):0.5704\n",
      "LightGBM:\n",
      "Best Train Score (F1-Score): 0.9940\n",
      "Best Estimator: Pipeline(steps=[('model', LGBMClassifier(n_estimators=200))])\n",
      "Best Test Score (F1-Score):0.5699\n"
     ]
    }
   ],
   "source": [
    "# Print the best models and their scores\n",
    "for model_name, info in best_models.items():\n",
    "    print(f'{model_name}:')\n",
    "    print(f'Best Train Score (F1-Score): {info[\"train_score\"]:.4f}')\n",
    "    print(f'Best Estimator: {info[\"best_estimator\"]}')\n",
    "    # Predict on the test set\n",
    "    y_pred = info[\"best_estimator\"].predict(X_test)\n",
    "    # Calculate the macro F1-score on the test set\n",
    "    test_score = f1_score(y_test, y_pred, average='macro')\n",
    "    print(f\"Best Test Score (F1-Score):{test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our best model was the Random Forest, which did really well in training with a high F1-score (0.9927) by using many decision trees together. But, its performance on new data wasn't as good, with a test F1-score of 0.5704.\n",
    "Now we will tune hyperparameters to see if we can make it perform better on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Optimizing Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] END ...................................n_estimators=100; total time=   6.8s\n",
      "[CV] END ...................................n_estimators=100; total time=   7.2s\n",
      "[CV] END ...................................n_estimators=100; total time=   7.1s\n",
      "[CV] END ...................................n_estimators=100; total time=   7.0s\n",
      "[CV] END ...................................n_estimators=100; total time=   7.1s\n",
      "[CV] END ...................................n_estimators=200; total time=  14.2s\n",
      "[CV] END ...................................n_estimators=200; total time=  14.2s\n",
      "[CV] END ...................................n_estimators=200; total time=  13.4s\n",
      "[CV] END ...................................n_estimators=200; total time=  13.4s\n",
      "[CV] END ...................................n_estimators=200; total time=  13.6s\n",
      "[CV] END ...................................n_estimators=300; total time=  19.6s\n",
      "[CV] END ...................................n_estimators=300; total time=  20.2s\n",
      "[CV] END ...................................n_estimators=300; total time=  20.9s\n",
      "[CV] END ...................................n_estimators=300; total time=  20.0s\n",
      "[CV] END ...................................n_estimators=300; total time=  20.6s\n",
      "Best Test F1-Score: 0.1511627906976744\n",
      "Training F1-Score of the Best Model: 0.9926201333200769\n",
      "Best Estimator: RandomForestClassifier(n_estimators=300, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# Create Classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# GridSearch\n",
    "scorer = make_scorer(f1_score)\n",
    "grid_search = GridSearchCV(rf_classifier, param_grid, scoring=scorer, cv=5,verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "training_f1 = grid_search.best_score_\n",
    "y_pred=best_model.predict(X_test)\n",
    "test_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Best Test F1-Score:\", test_f1)\n",
    "print(\"Training F1-Score of the Best Model:\", training_f1)\n",
    "print(\"Best Estimator:\", best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Test F1-Score: 0.5722179600373739\n",
      "Training F1-Score of the Best Model: 0.9926201333200769\n",
      "Best Estimator: RandomForestClassifier(n_estimators=300, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "test_f1 = f1_score(y_test, y_pred,average='macro')\n",
    "\n",
    "# Print results\n",
    "print(\"Best Test F1-Score:\", test_f1)\n",
    "print(\"Training F1-Score of the Best Model:\", training_f1)\n",
    "print(\"Best Estimator:\", best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     10823\n",
      "           1       0.23      0.11      0.15       115\n",
      "\n",
      "    accuracy                           0.99     10938\n",
      "   macro avg       0.61      0.55      0.57     10938\n",
      "weighted avg       0.98      0.99      0.98     10938\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1-Score: 0.5722179600373739\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "\n",
    "# Confussion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "print(\"Test F1-Score:\", test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import model into a Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as rf_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model to a pickle file\n",
    "model_filename = 'rf_model.pkl'\n",
    "joblib.dump(best_model, model_filename)\n",
    "\n",
    "print(\"Model saved as\", model_filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
